ğŸš€ Hybrid Retrieval-Augmented Generation (RAG) System

Final Project â€“ Advanced AI / CSC 790

This repository contains a Hybrid Retrieval-Augmented Generation (RAG) system built with:

FastAPI backend

BM25 Indexing (lexical retrieval)

Dense vector search using Chroma + bge-m3 embeddings

Reranking using bge-reranker

Local LLM generation using Ollama

Answer verification using Qwen / Llama models

SQuAD v1.1 dataset

This system retrieves relevant documents, generates answers, and checks for hallucinations.

ğŸ“ Project Structure
Mahi_Hybrid_RAG/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # FastAPI entry point
â”‚   â”œâ”€â”€ bm25_indexer.py        # BM25 lexical search
â”‚   â”œâ”€â”€ chroma_store.py        # Vector DB (Chroma)
â”‚   â”œâ”€â”€ data_processor.py      # Dataset loading, preprocessing, chunking
â”‚   â”œâ”€â”€ hybrid_retriever.py    # Hybrid BM25 + Embeddings retrieval
â”‚   â”œâ”€â”€ answer_verifier.py     # LLM-based answer verification
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py            # Configuration file
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ SQuAD-v1.1.csv         # Dataset used for retrieval
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ evaluate_system.py
â”‚   â”œâ”€â”€ create_plots.py
â”‚   â””â”€â”€ run_evaluation.py
â”‚
â”œâ”€â”€ results/ (ignored by git)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ simple_rag.py
â”œâ”€â”€ launch_rag_system.py
â””â”€â”€ README.md

âš™ï¸ Installation Instructions
1ï¸âƒ£ Create a virtual environment
python -m venv venv


Activate it:

Windows

venv\Scripts\activate


Mac/Linux

source venv/bin/activate


Install dependencies:

pip install -r requirements.txt

2ï¸âƒ£ Install Ollama + required models

Download Ollama:
https://ollama.com/download

Pull models:

ollama pull qwen2.5:7b-instruct-q3_k_m
ollama pull bge-m3
ollama pull xitao/bge-reranker-v2-m3


Make sure Ollama is running.

3ï¸âƒ£ Run the FastAPI backend

From the main project folder:

cd backend
python app.py


You'll see:

Uvicorn running on http://127.0.0.1:8000


Open Swagger UI:

ğŸ‘‰ http://localhost:8000/docs

ğŸ§ª API Endpoints
ğŸ” POST /search

Hybrid document retrieval (BM25 + embeddings).

Example:

{
  "query": "earthquake"
}

ğŸ¤– POST /rag

Retrieval + LLM generation + answer verification.

Example:

{
  "query": "What happened during the 2008 Sichuan earthquake?"
}


Response includes:

retrieved documents

generated answer

verification score

hallucination risk

ğŸ“˜ Dataset Used

This project uses SQuAD v1.1, stored at:

data/SQuAD-v1.1.csv


During preprocessing:

Text is chunked

Lexical + vector indexes are built

Chroma embeddings are created

ğŸ“Š Evaluation

Run evaluation script:

python run_evaluation.py


Produces:

retrieval metrics

generation metrics

verification accuracy

plots (if enabled)

Saved to:

results/
evaluation_results/

ğŸ§¹ What is not included (ignored via .gitignore)

data/chroma_db/

data/*.pkl

results/

evaluation_results/

backend/*.log

__pycache__/

.env

venv/
